{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hpputro/ml4sc/blob/main/3_Permodelan_Bahasa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Persiapan"
      ],
      "metadata": {
        "id": "EVVUUsZ4cml_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install antlr4-tools\n",
        "!pip install antlr4-python3-runtime==4.11.1\n",
        "!pip install pddlpy\n",
        "!antlr4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3o6eS1G55rY",
        "outputId": "7e905900-8894-4e2e-f6d0-6093bc3db779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting antlr4-tools\n",
            "  Downloading antlr4_tools-0.2-py3-none-any.whl (4.1 kB)\n",
            "Collecting install-jdk\n",
            "  Downloading install-jdk-0.3.0.tar.gz (3.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: install-jdk\n",
            "  Building wheel for install-jdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for install-jdk: filename=install_jdk-0.3.0-py3-none-any.whl size=3740 sha256=7cfc835dd1d33ab2325190156027797b0f062bd105405c78a470de565d971f79\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/a9/a3/03dc102cdcd442b9bca361f8c64fd4bb9b47ce75d9c8d56c91\n",
            "Successfully built install-jdk\n",
            "Installing collected packages: install-jdk, antlr4-tools\n",
            "Successfully installed antlr4-tools-0.2 install-jdk-0.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting antlr4-python3-runtime==4.11.1\n",
            "  Downloading antlr4_python3_runtime-4.11.1-py3-none-any.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: antlr4-python3-runtime\n",
            "Successfully installed antlr4-python3-runtime-4.11.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pddlpy\n",
            "  Downloading pddlpy-0.3.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: antlr4-python3-runtime>=4.9.3 in /usr/local/lib/python3.8/dist-packages (from pddlpy) (4.11.1)\n",
            "Installing collected packages: pddlpy\n",
            "Successfully installed pddlpy-0.3.3\n",
            "Downloading antlr4-4.11.1-complete.jar\n",
            "ANTLR Parser Generator  Version 4.11.1\n",
            " -o ___              specify output directory where all output is generated\n",
            " -lib ___            specify location of grammars, tokens files\n",
            " -atn                generate rule augmented transition network diagrams\n",
            " -encoding ___       specify grammar file encoding; e.g., euc-jp\n",
            " -message-format ___ specify output style for messages in antlr, gnu, vs2005\n",
            " -long-messages      show exception details when available for errors and warnings\n",
            " -listener           generate parse tree listener (default)\n",
            " -no-listener        don't generate parse tree listener\n",
            " -visitor            generate parse tree visitor\n",
            " -no-visitor         don't generate parse tree visitor (default)\n",
            " -package ___        specify a package/namespace for the generated code\n",
            " -depend             generate file dependencies\n",
            " -D<option>=value    set/override a grammar-level option\n",
            " -Werror             treat warnings as errors\n",
            " -XdbgST             launch StringTemplate visualizer on generated code\n",
            " -XdbgSTWait         wait for STViz to close before continuing\n",
            " -Xforce-atn         use the ATN simulator for all predictions\n",
            " -Xlog               dump lots of logging info to antlr-timestamp.log\n",
            " -Xexact-output-dir  all output goes into -o dir regardless of paths/package\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "metadata": {
        "id": "NGJyMzWy6Npx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24034fcb-6b23-40bc-d577-4afab4885d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dir\n",
        "!cp \"drive/MyDrive/Colab Notebooks/SourceCode/arithmeticLexer.py\" .\n",
        "!cp \"drive/MyDrive/Colab Notebooks/SourceCode/arithmeticParser.py\" ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF6C6l-C6ECH",
        "outputId": "c2048385-09f1-4e74-fd88-f1a886ca2bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AOiP0waqNL_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baca Source Code"
      ],
      "metadata": {
        "id": "WOck2beF6iO-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGTMtpE4Rw8e",
        "outputId": "9f593b8f-c628-4e8e-cd37-4f20782bb129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n",
            "0                       java = 123 * 4567\n",
            "1         private int mainan(String args)\n",
            "2    // two integer variables with values\n",
            "3                            int num1 = 5\n",
            "4                           int num2 = 15\n",
            "Name: source, dtype: object\n",
            "0     expression\n",
            "1    declaration\n",
            "2        comment\n",
            "3    declaration\n",
            "4    declaration\n",
            "Name: label, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/drive')\n",
        "df = pd.read_csv('/drive/My Drive/Colab Notebooks/SourceCode/sourcecode2.csv')\n",
        "X = df['source']\n",
        "y = df['label']\n",
        "print(X.head())\n",
        "print(y.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ubah ke Token Stream"
      ],
      "metadata": {
        "id": "Eq0fEv2f3U_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from antlr4 import *\n",
        "from arithmeticLexer import arithmeticLexer\n",
        "from arithmeticParser import arithmeticParser\n",
        "\n",
        "file = []\n",
        "for line, label in zip(X,y):\n",
        "  f = open(\"/drive/My Drive/Colab Notebooks/SourceCode/test3.txt\", \"w\")\n",
        "  f.write(line)\n",
        "  f.close()\n",
        "\n",
        "  input_stream = FileStream(\"/drive/My Drive/Colab Notebooks/SourceCode/test3.txt\")\n",
        "  lexer = arithmeticLexer(input_stream)\n",
        "  tokens = lexer.getAllTokens()\n",
        "  line = ''\n",
        "  for tk in tokens:\n",
        "    name = lexer.symbolicNames[tk.type]\n",
        "    line = line + ' ' + name\n",
        "  file.append([line,label])\n",
        "print(file)\n",
        "\n",
        "df2 = pd.DataFrame(file,columns=['source','label'])\n",
        "df2.to_csv('/drive/My Drive/Colab Notebooks/SourceCode/tokenstream2.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zb9RJxxG5qr",
        "outputId": "4c5e169d-cc31-43cb-a784-4266f9bc6a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[' VARIABLE EQ SCIENTIFIC_NUMBER TIMES SCIENTIFIC_NUMBER', 'expression'], [' VARIABLE VARIABLE VARIABLE LPAREN VARIABLE VARIABLE RPAREN', 'declaration'], [' DIV DIV VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE', 'comment'], [' VARIABLE VARIABLE EQ SCIENTIFIC_NUMBER', 'declaration'], [' VARIABLE VARIABLE EQ SCIENTIFIC_NUMBER', 'declaration'], [' VARIABLE VARIABLE', 'declaration'], [' DIV DIV VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE', 'comment'], [' VARIABLE EQ VARIABLE', 'expression'], [' DIV DIV VARIABLE VARIABLE VARIABLE', 'comment'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN VARIABLE PLUS VARIABLE PLUS VARIABLE PLUS VARIABLE PLUS VARIABLE PLUS VARIABLE RPAREN', 'expression'], [' VARIABLE VARIABLE POINT VARIABLE POINT VARIABLE', 'declaration'], [' VARIABLE EQ LPAREN SCIENTIFIC_NUMBER PLUS SCIENTIFIC_NUMBER RPAREN TIMES SCIENTIFIC_NUMBER', 'expression'], [' VARIABLE VARIABLE LPAREN VARIABLE VARIABLE RPAREN', 'declaration'], [' VARIABLE VARIABLE EQ VARIABLE', 'declaration'], [' VARIABLE VARIABLE EQ VARIABLE VARIABLE LPAREN VARIABLE POINT VARIABLE RPAREN', 'declaration'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN VARIABLE VARIABLE VARIABLE RPAREN', 'expression'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN VARIABLE VARIABLE VARIABLE RPAREN', 'expression'], [' VARIABLE POINT VARIABLE LPAREN RPAREN', 'expression'], [' VARIABLE EQ VARIABLE PLUS VARIABLE', 'expression'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN VARIABLE RPAREN', 'expression'], [' VARIABLE VARIABLE POINT VARIABLE POINT VARIABLE', 'declaration'], [' VARIABLE EQ SCIENTIFIC_NUMBER TIMES LPAREN SCIENTIFIC_NUMBER PLUS SCIENTIFIC_NUMBER RPAREN', 'expression'], [' VARIABLE VARIABLE VARIABLE LPAREN RPAREN', 'declaration'], [' VARIABLE VARIABLE', 'declaration'], [' VARIABLE VARIABLE EQ VARIABLE VARIABLE LPAREN VARIABLE POINT VARIABLE RPAREN', 'declaration'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN VARIABLE VARIABLE VARIABLE RPAREN', 'expression'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN VARIABLE VARIABLE VARIABLE RPAREN', 'expression'], [' VARIABLE POINT VARIABLE LPAREN RPAREN', 'expression'], [' VARIABLE EQ VARIABLE PLUS VARIABLE PLUS VARIABLE', 'expression'], [' VARIABLE VARIABLE POINT VARIABLE POINT VARIABLE', 'declaration'], [' VARIABLE EQ LPAREN VARIABLE MINUS LPAREN VARIABLE TIMES VARIABLE PLUS SCIENTIFIC_NUMBER TIMES VARIABLE TIMES VARIABLE RPAREN RPAREN DIV LPAREN SCIENTIFIC_NUMBER TIMES VARIABLE RPAREN', 'expression'], [' VARIABLE VARIABLE VARIABLE VARIABLE LPAREN VARIABLE VARIABLE RPAREN', 'declaration'], [' VARIABLE VARIABLE', 'declaration'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN VARIABLE VARIABLE VARIABLE VARIABLE RPAREN', 'expression'], [' DIV DIV VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE', 'comment'], [' VARIABLE VARIABLE EQ VARIABLE VARIABLE LPAREN VARIABLE POINT VARIABLE RPAREN', 'declaration'], [' DIV DIV VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE SCIENTIFIC_NUMBER VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE', 'comment'], [' VARIABLE VARIABLE DIV SCIENTIFIC_NUMBER EQ EQ SCIENTIFIC_NUMBER', 'control'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN VARIABLE PLUS VARIABLE VARIABLE VARIABLE VARIABLE POINT RPAREN', 'expression'], [' VARIABLE', 'control'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN VARIABLE PLUS VARIABLE VARIABLE VARIABLE VARIABLE POINT RPAREN', 'expression'], [' VARIABLE VARIABLE POINT VARIABLE POINT VARIABLE', 'declaration'], [' VARIABLE VARIABLE VARIABLE', 'declaration'], [' VARIABLE VARIABLE VARIABLE LPAREN VARIABLE VARIABLE RPAREN', 'declaration'], [' VARIABLE VARIABLE EQ VARIABLE VARIABLE LPAREN VARIABLE POINT VARIABLE RPAREN', 'declaration'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN VARIABLE VARIABLE VARIABLE RPAREN', 'expression'], [' VARIABLE VARIABLE EQ SCIENTIFIC_NUMBER', 'declaration'], [' DIV DIV VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE', 'comment'], [' VARIABLE VARIABLE EQ LPAREN VARIABLE EQ EQ SCIENTIFIC_NUMBER RPAREN', 'expression'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN VARIABLE PLUS VARIABLE VARIABLE PLUS VARIABLE RPAREN', 'expression'], [' VARIABLE VARIABLE', 'declaration'], [' VARIABLE VARIABLE VARIABLE VARIABLE LPAREN VARIABLE VARIABLE RPAREN', 'declaration'], [' VARIABLE VARIABLE', 'declaration'], [' VARIABLE LPAREN VARIABLE PLUS PLUS RPAREN', 'control'], [' VARIABLE VARIABLE EQ SCIENTIFIC_NUMBER', 'declaration'], [' VARIABLE LPAREN VARIABLE LT EQ VARIABLE RPAREN', 'control'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN TIMES RPAREN', 'expression'], [' DIV DIV VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE', 'comment'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN RPAREN', 'expression'], [' VARIABLE VARIABLE POINT VARIABLE POINT VARIABLE', 'declaration'], [' VARIABLE VARIABLE VARIABLE', 'declaration'], [' VARIABLE VARIABLE VARIABLE LPAREN VARIABLE VARIABLE RPAREN', 'declaration'], [' DIV DIV VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE', 'comment'], [' VARIABLE VARIABLE EQ VARIABLE VARIABLE LPAREN RPAREN', 'declaration'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE RPAREN', 'expression'], [' VARIABLE VARIABLE EQ SCIENTIFIC_NUMBER', 'declaration'], [' VARIABLE POINT VARIABLE LPAREN VARIABLE VARIABLE VARIABLE VARIABLE RPAREN', 'expression'], [' VARIABLE LPAREN VARIABLE LT VARIABLE RPAREN', 'control'], [' VARIABLE LPAREN VARIABLE PLUS PLUS RPAREN', 'control'], [' VARIABLE LPAREN VARIABLE EQ EQ SCIENTIFIC_NUMBER RPAREN', 'control'], [' VARIABLE POINT VARIABLE LPAREN TIMES PLUS RPAREN', 'expression'], [' VARIABLE', 'control'], [' DIV DIV VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE', 'comment'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN LPAREN VARIABLE RPAREN LPAREN VARIABLE RPAREN RPAREN', 'expression'], [' DIV TIMES VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE TIMES DIV', 'comment'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN RPAREN', 'expression'], [' VARIABLE VARIABLE POINT VARIABLE POINT VARIABLE', 'declaration'], [' VARIABLE VARIABLE VARIABLE', 'declaration'], [' VARIABLE VARIABLE VARIABLE LPAREN VARIABLE VARIABLE RPAREN', 'declaration'], [' VARIABLE VARIABLE', 'declaration'], [' DIV DIV VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE', 'comment'], [' VARIABLE VARIABLE EQ VARIABLE VARIABLE LPAREN VARIABLE POINT VARIABLE RPAREN', 'declaration'], [' VARIABLE LPAREN VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE RPAREN', 'expression'], [' VARIABLE VARIABLE LT VARIABLE', 'control'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN VARIABLE VARIABLE VARIABLE VARIABLE RPAREN', 'expression'], [' VARIABLE LPAREN VARIABLE MINUS VARIABLE RPAREN', 'control'], [' VARIABLE EQ SCIENTIFIC_NUMBER', 'expression'], [' VARIABLE LPAREN VARIABLE LT VARIABLE RPAREN', 'control'], [' VARIABLE LPAREN VARIABLE MINUS SCIENTIFIC_NUMBER RPAREN', 'control'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN RPAREN', 'expression'], [' VARIABLE', 'control'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN VARIABLE PLUS VARIABLE RPAREN', 'expression'], [' VARIABLE PLUS PLUS', 'expression'], [' DIV DIV TIMES TIMES VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE VARIABLE TIMES TIMES DIV DIV', 'comment'], [' VARIABLE POINT VARIABLE POINT VARIABLE LPAREN RPAREN', 'expression'], [' VARIABLE PLUS PLUS', 'expression']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF IDF"
      ],
      "metadata": {
        "id": "HgrIF_ew3ZNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dengan TF IDF Vectorizer"
      ],
      "metadata": {
        "id": "LA2Byoxp4HnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=3, norm='l2', encoding='latin-1', ngram_range=(1, 2))\n",
        "ft = tfidf.fit_transform(file)\n",
        "features = ft.toarray()\n",
        "print(tfidf.get_feature_names_out())\n",
        "labels = df.label\n",
        "print(features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPA7olSLZLh3",
        "outputId": "ea989c10-6986-4671-eb69-a8479426350f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['div' 'div div' 'div variable' 'eq' 'eq eq' 'eq lparen'\n",
            " 'eq scientific_number' 'eq variable' 'lparen' 'lparen rparen'\n",
            " 'lparen scientific_number' 'lparen variable' 'lt' 'lt variable' 'minus'\n",
            " 'plus' 'plus plus' 'plus rparen' 'plus scientific_number' 'plus variable'\n",
            " 'point' 'point variable' 'rparen' 'scientific_number'\n",
            " 'scientific_number rparen' 'scientific_number times' 'times'\n",
            " 'times variable' 'variable' 'variable eq' 'variable lparen' 'variable lt'\n",
            " 'variable minus' 'variable plus' 'variable point' 'variable rparen'\n",
            " 'variable times' 'variable variable']\n",
            "(96, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dengan Count Vectorizer & TF IDF Transformer"
      ],
      "metadata": {
        "id": "V4BN3OSA4MWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(df2['source'])\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "print(X_train_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_h8np_OtZvS6",
        "outputId": "a8c96322-e952-43b2-cff8-9a1a415b25e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 10)\t0.1423281276855254\n",
            "  (0, 9)\t0.48071131576144577\n",
            "  (0, 8)\t0.797641628559877\n",
            "  (0, 1)\t0.3353016065526375\n",
            "  (1, 10)\t0.9087711396736358\n",
            "  (1, 7)\t0.29507203840442203\n",
            "  (1, 2)\t0.29507203840442203\n",
            "  (2, 10)\t0.6572636295029801\n",
            "  (2, 0)\t0.7536607468434118\n",
            "  (3, 10)\t0.4794378367086556\n",
            "  (3, 8)\t0.6717217163680992\n",
            "  (3, 1)\t0.5647382548505274\n",
            "  (4, 10)\t0.4794378367086556\n",
            "  (4, 8)\t0.6717217163680992\n",
            "  (4, 1)\t0.5647382548505274\n",
            "  (5, 10)\t1.0\n",
            "  (6, 10)\t0.812817694200482\n",
            "  (6, 0)\t0.5825181507855456\n",
            "  (7, 10)\t0.6471861817537802\n",
            "  (7, 1)\t0.7623319789612417\n",
            "  (8, 10)\t0.463622721859743\n",
            "  (8, 0)\t0.8860327148448658\n",
            "  (9, 10)\t0.5209820923310365\n",
            "  (9, 7)\t0.09397748554500836\n",
            "  (9, 6)\t0.23052786561260744\n",
            "  :\t:\n",
            "  (88, 8)\t0.47592127632423786\n",
            "  (88, 7)\t0.2757347966119527\n",
            "  (88, 4)\t0.7113738802320405\n",
            "  (88, 2)\t0.2757347966119527\n",
            "  (89, 10)\t0.5465335477275783\n",
            "  (89, 7)\t0.295759773728239\n",
            "  (89, 6)\t0.7255021665693002\n",
            "  (89, 2)\t0.295759773728239\n",
            "  (90, 10)\t1.0\n",
            "  (91, 10)\t0.6805236931518441\n",
            "  (91, 7)\t0.22096158708663882\n",
            "  (91, 6)\t0.54202134434701\n",
            "  (91, 5)\t0.3813821172990969\n",
            "  (91, 2)\t0.22096158708663882\n",
            "  (92, 10)\t0.17566160890702154\n",
            "  (92, 5)\t0.9844506077788752\n",
            "  (93, 10)\t0.45283769211181424\n",
            "  (93, 9)\t0.6797569542415891\n",
            "  (93, 0)\t0.5769475780025806\n",
            "  (94, 10)\t0.5465335477275783\n",
            "  (94, 7)\t0.295759773728239\n",
            "  (94, 6)\t0.7255021665693002\n",
            "  (94, 2)\t0.295759773728239\n",
            "  (95, 10)\t0.17566160890702154\n",
            "  (95, 5)\t0.9844506077788752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Klasifikasi"
      ],
      "metadata": {
        "id": "FwfnUhMw3gTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(X_train_tfidf, labels)"
      ],
      "metadata": {
        "id": "sRhHxIjLcbeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediksi"
      ],
      "metadata": {
        "id": "tcZUFuJT3kOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dari Token Stream"
      ],
      "metadata": {
        "id": "TFcxhp_U36MT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(clf.predict(count_vect.transform([\"variable plus variable\"])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVp9vRrM3moF",
        "outputId": "a11e8f30-9e7e-4d4f-8d33-e239c966a023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['expression']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dari Baris Source Code"
      ],
      "metadata": {
        "id": "u-fVzXPn3-dG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/drive/My Drive/Colab Notebooks/SourceCode/test3.txt\", \"w\")\n",
        "f.write(\"// ini komentar\")\n",
        "f.close()\n",
        "\n",
        "input_stream = FileStream(\"/drive/My Drive/Colab Notebooks/SourceCode/test3.txt\")\n",
        "lexer = arithmeticLexer(input_stream)\n",
        "tokens = lexer.getAllTokens()\n",
        "line = ''\n",
        "for tk in tokens:\n",
        "  name = lexer.symbolicNames[tk.type]\n",
        "  line = line + ' ' + name\n",
        "print(clf.predict(count_vect.transform([line])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jIzZPbrjMdx",
        "outputId": "f2b14d76-9d47-41e4-cae2-0494b7b05243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['comment']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1_xXwbZwI8Xm4z_Glu9i9OOcoKC9zuyzr",
      "authorship_tag": "ABX9TyPDU/6RUqufG5e3jE5Y0jvz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}